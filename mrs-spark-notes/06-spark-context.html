<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title></title>
  <meta content="text/html; charset=UTF-8" http-equiv="Content-Type">
  <meta name="description" content="">
  <meta name="generator" content="bookdown <!--bookdown:version--> and GitBook 2.6.7">

  <meta property="og:title" content="" />
  <meta property="og:type" content="book" />
  
  
  
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="" />
  
  
  




  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  
<!--bookdown:link_prev-->
<!--bookdown:link_next-->

<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/htmlwidgets-0.6.1/htmlwidgets.js"></script>
<link href="libs/plotlyjs-1.10.1/plotly-htmlwidgets.css" rel="stylesheet" />
<script src="libs/plotlyjs-1.10.1/plotly-latest.min.js"></script>
<script src="libs/plotly-binding-3.5.5/plotly.js"></script>
<script src="libs/d3-3.5.5/d3.min.js"></script>
<script src="libs/d3-grid-0.1.0/d3-grid.js"></script>
<script src="libs/dimple-2.1.6/dimple.min.js"></script>
<script src="libs/dimple-binding-0.1/dimple.js"></script>


<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>


<!--bookdown:title:start-->
<!--bookdown:title:end-->

<!--bookdown:toc:start-->
  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">
<!--bookdown:toc2:start-->
<ul>
<li><a href="#part-data-manipulation-and-data-aggregation">(PART) Data Manipulation and Data Aggregation</a></li>
<li><a href="#starting-your-machine-learning-pipeline"><span class="toc-section-number">1</span> Starting Your Machine Learning Pipeline</a><ul>
<li><a href="#todo"><span class="toc-section-number">1.1</span> todo</a></li>
<li><a href="#finding-the-sparkr-library"><span class="toc-section-number">1.2</span> Finding the SparkR Library</a></li>
<li><a href="#creating-a-spark-context"><span class="toc-section-number">1.3</span> Creating a Spark Context</a></li>
<li><a href="#creating-dataframes"><span class="toc-section-number">1.4</span> Creating DataFrames</a><ul>
<li><a href="#from-local-r-data.frames"><span class="toc-section-number">1.4.1</span> From Local R data.frames</a></li>
<li><a href="#creating-dataframes-from-csv-files"><span class="toc-section-number">1.4.2</span> Creating DataFrames from CSV Files</a></li>
</ul></li>
</ul></li>
<li><a href="#exploratory-data-analysis-with-sparkr"><span class="toc-section-number">2</span> Exploratory Data Analysis with SparkR</a><ul>
<li><a href="#sparkr-the-explorer"><span class="toc-section-number">2.1</span> SparkR the Explorer</a></li>
<li><a href="#doing-data-aggregations-with-sparkr-efficiently"><span class="toc-section-number">2.2</span> Doing Data Aggregations with SparkR Efficiently</a></li>
<li><a href="#from-spark-dataframes-to-local-dataframes"><span class="toc-section-number">2.3</span> From Spark DataFrames to Local Dataframes</a></li>
<li><a href="#plotting-results"><span class="toc-section-number">2.4</span> Plotting Results</a></li>
</ul></li>
<li><a href="#data-manipulation-with-sparkr"><span class="toc-section-number">3</span> Data Manipulation with SparkR</a><ul>
<li><a href="#data-aggregations"><span class="toc-section-number">3.1</span> Data Aggregations</a></li>
<li><a href="#collecting-results-to-local-dataframes"><span class="toc-section-number">3.2</span> Collecting Results to Local Dataframes</a></li>
<li><a href="#dimple-bar-charts"><span class="toc-section-number">3.3</span> Dimple Bar Charts</a></li>
<li><a href="#merging-data"><span class="toc-section-number">3.4</span> Merging Data</a></li>
<li><a href="#exploring-credit-scores-for-mortgage-borrowers"><span class="toc-section-number">3.5</span> Exploring Credit Scores for Mortgage Borrowers</a></li>
</ul></li>
</ul>
<!--bookdown:toc2:end-->
      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./"></a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<!--bookdown:toc:end-->
<!--bookdown:body:start-->
<div id="part-data-manipulation-and-data-aggregation" class="section level1 unnumbered">
<h1>(PART) Data Manipulation and Data Aggregation</h1>
</div>
<div id="starting-your-machine-learning-pipeline" class="section level1">
<h1><span class="header-section-number">1</span> Starting Your Machine Learning Pipeline</h1>
<div id="todo" class="section level2">
<h2><span class="header-section-number">1.1</span> todo</h2>
<ul>
<li>since rmarkdown/knitr start a new session when building docs, can’t access current spark context</li>
<li>either build from scratch, or persist rdds/dfs</li>
<li>alternatively, make ipynb in jupyter and save as md and render in book as md</li>
<li>no console output from rxHadoop shell wrappers, need to sink and show if want to see output</li>
<li>to cache results, might make sense to persist DFs and then reuse when needed</li>
<li>take a look at <a href="https://github.com/hoxo-m/SparkRext">sparkr-ext</a></li>
<li>and SKKU-SKT/ggplot2.SparkR</li>
</ul>
<p>The first steps to start your machine learning and data science pipeline is to set your compute environment, and point to your data.</p>
<p>In Spark, you’ll need to create a SparkContext. This constructor provides Spark with the details of the cluster: how and where to access it, additional package directories, etc. You’ll use this constructor to create new RDDs or DataFrames.</p>
</div>
<div id="finding-the-sparkr-library" class="section level2">
<h2><span class="header-section-number">1.2</span> Finding the SparkR Library</h2>
<p>In order to create a Spark Context from your RStudio Server environment, you’ll need to access the SparkR library. Since Spark 1.4, SparkR has shipped the R API directly with its core implementation. Therefore, since 1.4 you do not need to install Spark from CRAN or a development version from github, but you need to add the SparkR library to your library paths in order to access it. A system variable called “SPARK_HOME” has been set that points to the Spark installation directory, and in it you’ll find subdirectories, “R/lib”, containing the SparkR library.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">list.files</span>(<span class="kw">file.path</span>(<span class="kw">Sys.getenv</span>(<span class="st">&quot;SPARK_HOME&quot;</span>), <span class="st">&quot;R&quot;</span>, <span class="st">&quot;lib&quot;</span>))</code></pre></div>
<pre><code>## [1] &quot;SparkR&quot;     &quot;sparkr.zip&quot;</code></pre>
<p>To add the SparkR library to your library paths, use the <code>.libPaths</code> function to include the directory in the search path for R’s library tree. The library paths could also be changed from in the <code>Rprofile</code>, either for the user or system wide. See the help on <code>?StartUp</code> for more details on R’s startup mechanism.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">.libPaths</span>(<span class="kw">c</span>(<span class="kw">file.path</span>(<span class="kw">Sys.getenv</span>(<span class="st">&quot;SPARK_HOME&quot;</span>), <span class="st">&quot;R&quot;</span>, <span class="st">&quot;lib&quot;</span>), <span class="kw">.libPaths</span>()))</code></pre></div>
</div>
<div id="creating-a-spark-context" class="section level2">
<h2><span class="header-section-number">1.3</span> Creating a Spark Context</h2>
<p>To create a SparkContext, you should use the <code>spark.init</code> function and pass in options for the environment parameters, application properties, any spark packages depended on, and any other additional Spark parameters. In order to create and manipulate DataFrames, we will need a SQLContext, which can be created from the SparkContext using the <code>sparkRSQL.init</code> function.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(SparkR)

sparkEnvir &lt;-<span class="st"> </span><span class="kw">list</span>(<span class="dt">spark.executor.instance =</span> <span class="st">&#39;10&#39;</span>,
                   <span class="dt">spark.yarn.executor.memoryOverhead =</span> <span class="st">&#39;8000&#39;</span>)

sc &lt;-<span class="st"> </span><span class="kw">sparkR.init</span>(
  <span class="dt">sparkEnvir =</span> sparkEnvir,
  <span class="dt">sparkPackages =</span> <span class="st">&quot;com.databricks:spark-csv_2.10:1.3.0&quot;</span>
)

sqlContext &lt;-<span class="st"> </span><span class="kw">sparkRSQL.init</span>(sc)</code></pre></div>
<p>We added the <code>sparkPackages</code> argument and set it to the value of <code>spark-csv</code> package provided by databricks. This will allow us to read csv objects into Spark DataFrames. Databricks are a prominent vendor for Spark, and are developers of many Spark packages (think of them as the RStudio of the Spark ecosystem).</p>
<p>After you are done using your Spark session, you can terminate your backend to Spark by running <code>sparkR.stop()</code>.</p>
</div>
<div id="creating-dataframes" class="section level2">
<h2><span class="header-section-number">1.4</span> Creating DataFrames</h2>
<p>Using our <code>sqlContext</code> variable, we can create DataFrames from local R data.frames, from Hive tables, or from other data sources. You could create a Spark DataFrame from a local R data.frame using the <code>createDataFrame</code> function,</p>
<div id="from-local-r-data.frames" class="section level3">
<h3><span class="header-section-number">1.4.1</span> From Local R data.frames</h3>
<p>Creating Spark DataFrames from local R <code>data.frames</code> might not seem like a great idea. After all, if it can fit in an R data.frame, that means it can fit in a single node’s memory, so why distribute it? It might be that you are testing your methods out on a sample dataset, and eventually you plan to scale out your analysis to larger datasets when your tests have passed. For expository purposes, this is a useful exercise, as it’ll expose you to the fundamentals of Spark DataFrames, and the SparkR syntax.</p>
<p>As a first example, we’ll import data from the <code>nycflight13</code> package into a Spark DataFrame, and use it’s data aggregation functions to tabulate the number of flights to each destination of flights originating from JFK.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(nycflights13)
flights &lt;-<span class="st"> </span><span class="kw">createDataFrame</span>(sqlContext, nycflights13::flights)
jfk_flights &lt;-<span class="st"> </span><span class="kw">filter</span>(flights, flights$origin ==<span class="st"> &quot;JFK&quot;</span>)
<span class="co"># Group the flights by destination and aggregate by the number of flights</span>
dest_flights &lt;-<span class="st"> </span><span class="kw">summarize</span>(
  <span class="kw">group_by</span>(jkf_flights, jfk_flights$dest), 
  <span class="dt">count =</span> <span class="kw">n</span>(jfk_flights$dest)
  )
<span class="co"># Now sort by the `count` column and print the first few rows</span>
<span class="kw">head</span>(<span class="kw">arrange</span>(dest_flights, <span class="kw">desc</span>(dest_flights$count)))</code></pre></div>
<p>This same analysis could be streamlined using the <code>%&gt;%</code> operator exposed by the magrittr package to improve the readability of the pipeline:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(magrittr)
dest_flights &lt;-<span class="st"> </span><span class="kw">filter</span>(flights, flights$origin ==<span class="st"> &quot;JFK&quot;</span>) %&gt;%<span class="st"> </span>
<span class="st">  </span><span class="kw">group_by</span>(flights$dest) %&gt;%<span class="st"> </span>
<span class="st">  </span><span class="kw">summarize</span>(<span class="dt">count =</span> <span class="kw">n</span>(flights$dest))
dest_flights %&gt;%<span class="st"> </span><span class="kw">arrange</span>(<span class="kw">desc</span>(dest_flights$count)) %&gt;%<span class="st"> </span>head</code></pre></div>
</div>
<div id="creating-dataframes-from-csv-files" class="section level3">
<h3><span class="header-section-number">1.4.2</span> Creating DataFrames from CSV Files</h3>
<p>Since we imported the spark-csv package, we can import CSV files into DataFrames. We will be using the full airlines dataset, which I assume you have already ingested into Blob storage by following the steps in Section @ref(ingestion).</p>
<p>We have saved in our data directory a couple of data directories (virtually, everything in Azure Storage is a simple blob!). Let’s see what we have in our directory using the <code>rxHadoopListFiles</code> command, which is simply a wrapper to hadoop shell command <code>hadoop fs -ls</code></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">data_dir &lt;-<span class="st"> &quot;/user/RevoShare/alizaidi&quot;</span>
<span class="kw">rxHadoopListFiles</span>(data_dir)</code></pre></div>
<p>Taking a look at the individual directories, we can see how many files there are for the Airlines directory and Weather directory</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">rxHadoopCommand</span>(<span class="st">&quot;fs -ls /user/RevoShare/alizaidi/AirOnTimeCSV | head&quot;</span>)
<span class="kw">rxHadoopCommand</span>(<span class="st">&quot;fs -ls /user/RevoShare/alizaidi/delayDataLarge/WeatherRaw | head&quot;</span>)</code></pre></div>
<p>Let’s read the airlines directory and the weather directory to Spark DataFrames. We will use the <code>read.df</code> function from the <code>spark.csv</code> package.</p>
<p>Note that it took more than 6 minutes to load our airlines data into Spark DataFrames. However, subsequent operations on the <code>airDF</code> object will occur in-memory, and should be very fast.</p>
<p>Let’s count the number of rows in each of our DataFrames and print the first few rows:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(SparkR)
<span class="kw">lapply</span>(<span class="kw">list</span>(airDF, weatherDF), count)
<span class="co"># [[1]]</span>
<span class="co"># [1] 148619655</span>
<span class="co"># </span>
<span class="co"># [[2]]</span>
<span class="co"># [1] 14829028</span>

<span class="kw">lapply</span>(<span class="kw">list</span>(airDF, weatherDF), head)
<span class="co"># [[1]]</span>
<span class="co">#   YEAR MONTH DAY_OF_MONTH DAY_OF_WEEK    FL_DATE UNIQUE_CARRIER TAIL_NUM FL_NUM</span>
<span class="co"># 1 1987    10            1           4 1987-10-01             AA               1</span>
<span class="co"># 2 1987    10            2           5 1987-10-02             AA               1</span>
<span class="co"># 3 1987    10            3           6 1987-10-03             AA               1</span>
<span class="co"># 4 1987    10            4           7 1987-10-04             AA               1</span>
<span class="co"># 5 1987    10            5           1 1987-10-05             AA               1</span>
<span class="co"># 6 1987    10            6           2 1987-10-06             AA               1</span>
<span class="co">#   ORIGIN_AIRPORT_ID ORIGIN ORIGIN_STATE_ABR DEST_AIRPORT_ID DEST DEST_STATE_ABR</span>
<span class="co"># 1             12478    JFK               NY           12892  LAX             CA</span>
<span class="co"># 2             12478    JFK               NY           12892  LAX             CA</span>
<span class="co"># 3             12478    JFK               NY           12892  LAX             CA</span>
<span class="co"># 4             12478    JFK               NY           12892  LAX             CA</span>
<span class="co"># 5             12478    JFK               NY           12892  LAX             CA</span>
<span class="co"># 6             12478    JFK               NY           12892  LAX             CA</span>
<span class="co">#   CRS_DEP_TIME DEP_TIME DEP_DELAY DEP_DELAY_NEW DEP_DEL15 DEP_DELAY_GROUP TAXI_OUT</span>
<span class="co"># 1          900      901         1             1         0               0         </span>
<span class="co"># 2          900      901         1             1         0               0         </span>
<span class="co"># 3          900      859        -1             0         0              -1         </span>
<span class="co"># 4          900      900         0             0         0               0         </span>
<span class="co"># 5          900      902         2             2         0               0         </span>
<span class="co"># 6          900      900         0             0         0               0         </span>
<span class="co">#   WHEELS_OFF WHEELS_ON TAXI_IN CRS_ARR_TIME ARR_TIME ARR_DELAY ARR_DELAY_NEW</span>
<span class="co"># 1                                      1152     1117       -35             0</span>
<span class="co"># 2                                      1152     1137       -15             0</span>
<span class="co"># 3                                      1152     1111       -41             0</span>
<span class="co"># 4                                      1152     1116       -36             0</span>
<span class="co"># 5                                      1152     1119       -33             0</span>
<span class="co"># 6                                      1152       NA        NA            NA</span>
<span class="co">#   ARR_DEL15 ARR_DELAY_GROUP CANCELLED CANCELLATION_CODE DIVERTED CRS_ELAPSED_TIME</span>
<span class="co"># 1         0              -2         0                          0              352</span>
<span class="co"># 2         0              -1         0                          0              352</span>
<span class="co"># 3         0              -2         0                          0              352</span>
<span class="co"># 4         0              -2         0                          0              352</span>
<span class="co"># 5         0              -2         0                          0              352</span>
<span class="co"># 6        NA              NA         0                          1              352</span>
<span class="co">#   ACTUAL_ELAPSED_TIME AIR_TIME FLIGHTS DISTANCE DISTANCE_GROUP CARRIER_DELAY</span>
<span class="co"># 1                 316                1     2475             10              </span>
<span class="co"># 2                 336                1     2475             10              </span>
<span class="co"># 3                 312                1     2475             10              </span>
<span class="co"># 4                 316                1     2475             10              </span>
<span class="co"># 5                 317                1     2475             10              </span>
<span class="co"># 6                  NA                1     2475             10              </span>
<span class="co">#   WEATHER_DELAY NAS_DELAY SECURITY_DELAY LATE_AIRCRAFT_DELAY </span>
<span class="co"># 1                                                            </span>
<span class="co"># 2                                                            </span>
<span class="co"># 3                                                            </span>
<span class="co"># 4                                                            </span>
<span class="co"># 5                                                            </span>
<span class="co"># 6                                                            </span>
<span class="co"># </span>
<span class="co"># [[2]]</span>
<span class="co">#   Visibility DryBulbCelsius DewPointCelsius RelativeHumidity WindSpeed Altimeter</span>
<span class="co"># 1   4.000000       0.000000       -1.000000        92.000000  0.000000 29.690000</span>
<span class="co"># 2  10.000000       7.000000       -3.000000        49.000000 11.000000 29.790000</span>
<span class="co"># 3   3.000000       1.000000        0.000000        92.000000  3.000000 29.710000</span>
<span class="co"># 4  10.000000       7.000000       -5.000000        42.000000 18.000000 29.710000</span>
<span class="co"># 5   1.250000       3.000000        0.000000        82.000000  6.000000 29.720000</span>
<span class="co"># 6  10.000000       8.000000       -4.000000        44.000000 14.000000 29.770000</span>
<span class="co">#   AdjustedYear AdjustedMonth AdjustedDay AdjustedHour AirportID</span>
<span class="co"># 1         2007             5           4           18     15177</span>
<span class="co"># 2         2007             5           4            6     15177</span>
<span class="co"># 3         2007             5           4           17     15177</span>
<span class="co"># 4         2007             5           4            9     15177</span>
<span class="co"># 5         2007             5           4           10     15177</span>
<span class="co"># 6         2007             5           4            7     15177</span></code></pre></div>
</div>
</div>
</div>
<div id="exploratory-data-analysis-with-sparkr" class="section level1">
<h1><span class="header-section-number">2</span> Exploratory Data Analysis with SparkR</h1>
<div id="sparkr-the-explorer" class="section level2">
<h2><span class="header-section-number">2.1</span> SparkR the Explorer</h2>
<p>SparkR has a limited API for modeling. As of 1.6.1, the only supported modeling function in SparkR is a glm. There are many more available modeling functions in the R Server <code>RevoScaleR</code> library that can be computed using a Spark compute context. We will discuss this in more detail in the subsequent chapters.</p>
<p>While limited in modeling, SparkR shows its versatility for data exploration. We show how easy it is to create data exploration pipelines with SparkR and open source R packages.</p>
</div>
<div id="doing-data-aggregations-with-sparkr-efficiently" class="section level2">
<h2><span class="header-section-number">2.2</span> Doing Data Aggregations with SparkR Efficiently</h2>
<p>Since Spark evaluates objects lazily, tremendous speedups can be achieved by putting a little thought into our data analysis pipelines. In ths section, we will analyze the average arrival delay for flights and group them by carrier, origin and destination. These few feature variables are the only ones we need, so we can remove the redundant columns.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">select_cols &lt;-<span class="st"> </span>function(<span class="dt">sparkDF =</span> airDF) {
  
  <span class="kw">library</span>(magrittr)
  
  sparkDF %&gt;%<span class="st"> </span>
<span class="st">    </span>SparkR::<span class="kw">select</span>(airDF$FL_DATE, airDF$DAY_OF_WEEK,
                   airDF$UNIQUE_CARRIER, airDF$ORIGIN,
                   airDF$DEST, airDF$ARR_DELAY) -&gt;<span class="st"> </span>skinny_df
  
  skinny_df %&lt;&gt;%<span class="st"> </span>SparkR::<span class="kw">rename</span>(
    <span class="dt">flight_date =</span> skinny_df$FL_DATE,
    <span class="dt">day_of_week =</span> skinny_df$DAY_OF_WEEK,
    <span class="dt">carrier =</span> skinny_df$UNIQUE_CARRIER, 
    <span class="dt">origin =</span> skinny_df$ORIGIN,
    <span class="dt">destination =</span> skinny_df$DEST, 
    <span class="dt">arrival_delay =</span> skinny_df$ARR_DELAY
  )
  
  
  <span class="kw">return</span>(skinny_df)
  
}

air_df &lt;-<span class="st"> </span><span class="kw">select_cols</span>()</code></pre></div>
<p>The function above creates a transformation on our airlines dataset and renames the columns we need for our analysis. At this point, we don’t have any actions yet, so this is simply a promise the Spark interpreter has given us for later evaluation.</p>
</div>
<div id="from-spark-dataframes-to-local-dataframes" class="section level2">
<h2><span class="header-section-number">2.3</span> From Spark DataFrames to Local Dataframes</h2>
<p>For our next step, we will group by carrier, origin and destination, and calculate the average arrival delay. Our resulting dataframe should be rather condensed, so we will collect our results and save them to a local R <code>data.frame</code>. Observe how simple it is to create a pipeline that starts with a Spark DataFrame and outputs a local data.frame you can interact with locally.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">agg_delay &lt;-<span class="st"> </span>function(<span class="dt">airdf =</span> air_df) {
  
  <span class="kw">library</span>(magrittr)
  
  airdf %&gt;%<span class="st"> </span>SparkR::<span class="kw">group_by</span>(airdf$carrier,
                             airdf$origin,
                             airdf$destination) %&gt;%<span class="st"> </span>
<span class="st">    </span>SparkR::<span class="kw">summarize</span>(<span class="dt">counts =</span> <span class="kw">n</span>(airdf$arrival_delay),
                      <span class="dt">ave_delay =</span> <span class="kw">mean</span>(airdf$arrival_delay)) -&gt;<span class="st"> </span>summary_df
  
  <span class="kw">return</span>(summary_df)
  
}

agg_df &lt;-<span class="st"> </span><span class="kw">agg_delay</span>()
agg_df_local &lt;-<span class="st"> </span>agg_df %&gt;%<span class="st"> </span><span class="kw">collect</span>() %&gt;%<span class="st"> </span>dplyr::tbl_df
<span class="kw">save</span>(agg_df_local, <span class="dt">file =</span> <span class="st">&quot;aggflightslocal.RData&quot;</span>)</code></pre></div>
<p>If you are familiar with the dplyr grammar of data manipulation, you should be ecstatic by how your knowledge transfers over directly to manipulating Spark dataframes (and you’ll probably just wonder why Spark DataFrames don’t just have a supported backend by dplyr yet). We saved our local data.frame to disk so we don’t have to re-run the Spark datasteps again.</p>
</div>
<div id="plotting-results" class="section level2">
<h2><span class="header-section-number">2.4</span> Plotting Results</h2>
<p>We deliberately kept the <strong>carrier</strong> column in our analysis, in case we wanted to visualize or analyze delays by that feature. For now, let us narrow our focus to simply the routes of our flights.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># load the agg_df_local calculated above</span>
<span class="kw">load</span>(<span class="st">&quot;aggflightslocal.RData&quot;</span>)

delays_routes &lt;-<span class="st"> </span>function(<span class="dt">delay_df =</span> agg_df_local) {
  
  <span class="kw">library</span>(dplyr)
  
  delay_df %&gt;%
<span class="st">    </span><span class="kw">group_by</span>(origin, destination) %&gt;%
<span class="st">    </span><span class="kw">summarize</span>(<span class="dt">total =</span> <span class="kw">sum</span>(counts), 
              <span class="dt">arrival_delay =</span> <span class="kw">weighted.mean</span>(ave_delay, counts)) -&gt;<span class="st"> </span>route_delays
  
  <span class="kw">return</span>(route_delays)
 
  
}

<span class="kw">delays_routes</span>()</code></pre></div>
<pre><code>## 
## Attaching package: &#39;dplyr&#39;</code></pre>
<pre><code>## The following objects are masked from &#39;package:SparkR&#39;:
## 
##     arrange, between, collect, count, cume_dist, dense_rank, desc,
##     distinct, explain, filter, first, group_by, intersect, lag,
##     last, lead, mutate, n, n_distinct, ntile, percent_rank,
##     rename, row_number, sample_frac, select, sql, summarize</code></pre>
<pre><code>## The following objects are masked from &#39;package:stats&#39;:
## 
##     filter, lag</code></pre>
<pre><code>## The following objects are masked from &#39;package:base&#39;:
## 
##     intersect, setdiff, setequal, union</code></pre>
<pre><code>## Source: local data frame [9,171 x 4]
## Groups: origin [?]
## 
##    origin destination total arrival_delay
##     (chr)       (chr) (dbl)         (dbl)
## 1     ABE         ALB     2    23.0000000
## 2     ABE         ATL 18482     7.4414566
## 3     ABE         AVP  1587     2.3238815
## 4     ABE         AZO     0           NaN
## 5     ABE         BDL     1     1.0000000
## 6     ABE         BHM     1    -3.0000000
## 7     ABE         BWI  2502     4.3033573
## 8     ABE         CLE  6331    -2.4669089
## 9     ABE         CLT  8531     0.1807525
## 10    ABE         CVG  6654     0.4804629
## ..    ...         ...   ...           ...</code></pre>
<p>Let us make a heatmap of the delays, by picking just a few routes. We will use the <code>ggplot</code> library to make our base plot, and then use the <code>plotly</code> package to make our plot more interactive!</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(ggplot2)

plot_route_delays &lt;-<span class="st"> </span>function(<span class="dt">min_routes =</span> <span class="dv">10</span>) {
  
  <span class="kw">library</span>(dplyr)
  <span class="kw">library</span>(ggplot2)
  
  gplot &lt;-<span class="st"> </span><span class="kw">delays_routes</span>() %&gt;%
<span class="st">    </span><span class="kw">filter</span>(total &gt;<span class="st"> </span>min_routes) %&gt;%<span class="st"> </span>
<span class="st">    </span><span class="kw">arrange</span>(<span class="kw">desc</span>(total)) %&gt;%<span class="st"> </span>
<span class="st">    </span><span class="kw">filter</span>(origin %in%<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;JFK&quot;</span>, <span class="st">&quot;LGA&quot;</span>, <span class="st">&quot;IAD&quot;</span>, <span class="st">&quot;DCA&quot;</span>,
                         <span class="st">&quot;ATL&quot;</span>, <span class="st">&quot;DFW&quot;</span>, <span class="st">&quot;ORD&quot;</span>, <span class="st">&quot;IAH&quot;</span>, 
                         <span class="st">&quot;DEN&quot;</span>, <span class="st">&quot;CLT&quot;</span>),
           destination %in%<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;ATL&quot;</span>, <span class="st">&quot;BDL&quot;</span>, <span class="st">&quot;BOS&quot;</span>, <span class="st">&quot;JFK&quot;</span>, 
                              <span class="st">&quot;IAD&quot;</span>, <span class="st">&quot;LGA&quot;</span>, <span class="st">&quot;DCA&quot;</span>, <span class="st">&quot;IAD&quot;</span>,
                              <span class="st">&quot;DFW&quot;</span>, <span class="st">&quot;ORD&quot;</span>, <span class="st">&quot;IAH&quot;</span>, <span class="st">&quot;DEN&quot;</span>, 
                              <span class="st">&quot;CLT&quot;</span>)) %&gt;%<span class="st"> </span>
<span class="st">    </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> origin, <span class="dt">y =</span> destination, <span class="dt">fill =</span> arrival_delay)) +<span class="st"> </span>
<span class="st">    </span><span class="kw">geom_tile</span>(<span class="dt">color =</span> <span class="st">&quot;white&quot;</span>) +<span class="st"> </span>
<span class="st">    </span><span class="kw">scale_fill_gradient</span>(<span class="dt">low =</span> <span class="st">&quot;white&quot;</span>, <span class="dt">high =</span> <span class="st">&quot;steelblue&quot;</span>)
  
  <span class="kw">return</span>(gplot)
  
}

gplot &lt;-<span class="st"> </span><span class="kw">plot_route_delays</span>(<span class="dv">100</span>) +<span class="st"> </span><span class="kw">theme_bw</span>()
<span class="kw">library</span>(plotly)
<span class="kw">ggplotly</span>(gplot, <span class="dt">width =</span> <span class="dv">650</span>)</code></pre></div>
<p><div id="htmlwidget-7875" style="width:650px;height:500px;" class="plotly html-widget"></div>
<script type="application/json" data-for="htmlwidget-7875">{"x":{"data":[{"x":[1,2,3,4,5,6,7,8,9,10],"y":[1,2,3,4,5,6,7,8,9,10,11,12],"z":[[null,0.575508881420848,0.52810844655813,0.527958749889444,0.637930784007805,0.592529207537495,0.606979625543442,0.695737837523735,0.679733144401821,0.706186984944412],[0.550064527797597,0.478892106542017,0.392950543566392,0.580948911381854,0.500382731139362,0.560446824006759,0.422893881898291,0.431219820318448,0.417954445634229,0.661827807649112],[0.706310281044572,0.617041907482155,0.413720353617263,0.593785183966634,0.588320991174162,0.722292138029002,0.539622151058074,0.729152775028315,0.235121036168544,0.718025885066374],[0.526218875795656,null,0.41856645037478,0.390148951560722,0.495561027048762,0.483323215537141,0.415191062301563,0.768243360314104,0.527959075751454,0.629939981047246],[0.552503822806452,0.47254206702059,null,0.49379845405737,0.517253988203036,0.580208947203045,0.371211099757297,0.659552591737778,0.220455537114002,0.586887051834747],[0.550608220037991,0.455340818477051,0.289705771862716,null,0.572198162858736,0.51572385106483,0.501481367157469,0.674510392168591,0.537271786336865,0.664792527515765],[0.599152232086551,0.388401707258818,0.358126994221729,0.532355896409273,null,0.381529665092533,0.491994416464964,0.879366384928629,0.404471396793396,0.528429427827822],[0.596156972849592,0.50128925203263,0,0.494277382737415,0.4949483797451,null,0.360495253604851,0.583528936440087,0.572680561027596,0.655904901246423],[0.597908251140293,0.475824911365917,0.326265883472013,0.524674898543362,0.544286048832883,0.478614059959527,null,0.632307970936729,0.479956367425385,0.621975497300887],[0.728801354712092,0.800136892737496,0.710030314747219,0.53663057361579,0.701170387224551,0.783289233033361,0.579615907525195,null,null,0.768124363798173],[0.80914732187602,0.728650036372322,0.314995103343137,0.715728072369897,0.673842272879803,0.752150813914015,0.702422145601397,null,null,0.714806355914222],[0.749297992062937,0.652862949154039,0.483269520157869,0.686424293549738,0.639263911488244,0.585397080131902,0.710643132564431,1,0.563974555015312,null]],"text":[[null,"origin: CLT<br>destination: ATL<br>arrival_delay: 8.11","origin: DCA<br>destination: ATL<br>arrival_delay: 7.08","origin: DEN<br>destination: ATL<br>arrival_delay: 7.07","origin: DFW<br>destination: ATL<br>arrival_delay: 9.47","origin: IAD<br>destination: ATL<br>arrival_delay: 8.48","origin: IAH<br>destination: ATL<br>arrival_delay: 8.8","origin: JFK<br>destination: ATL<br>arrival_delay: 10.73","origin: LGA<br>destination: ATL<br>arrival_delay: 10.38","origin: ORD<br>destination: ATL<br>arrival_delay: 10.96"],["origin: ATL<br>destination: BDL<br>arrival_delay: 7.56","origin: CLT<br>destination: BDL<br>arrival_delay: 6","origin: DCA<br>destination: BDL<br>arrival_delay: 4.13","origin: DEN<br>destination: BDL<br>arrival_delay: 8.23","origin: DFW<br>destination: BDL<br>arrival_delay: 6.47","origin: IAD<br>destination: BDL<br>arrival_delay: 7.78","origin: IAH<br>destination: BDL<br>arrival_delay: 4.78","origin: JFK<br>destination: BDL<br>arrival_delay: 4.97","origin: LGA<br>destination: BDL<br>arrival_delay: 4.68","origin: ORD<br>destination: BDL<br>arrival_delay: 9.99"],["origin: ATL<br>destination: BOS<br>arrival_delay: 10.96","origin: CLT<br>destination: BOS<br>arrival_delay: 9.02","origin: DCA<br>destination: BOS<br>arrival_delay: 4.58","origin: DEN<br>destination: BOS<br>arrival_delay: 8.51","origin: DFW<br>destination: BOS<br>arrival_delay: 8.39","origin: IAD<br>destination: BOS<br>arrival_delay: 11.31","origin: IAH<br>destination: BOS<br>arrival_delay: 7.33","origin: JFK<br>destination: BOS<br>arrival_delay: 11.46","origin: LGA<br>destination: BOS<br>arrival_delay: 0.69","origin: ORD<br>destination: BOS<br>arrival_delay: 11.22"],["origin: ATL<br>destination: CLT<br>arrival_delay: 7.04",null,"origin: DCA<br>destination: CLT<br>arrival_delay: 4.69","origin: DEN<br>destination: CLT<br>arrival_delay: 4.07","origin: DFW<br>destination: CLT<br>arrival_delay: 6.37","origin: IAD<br>destination: CLT<br>arrival_delay: 6.1","origin: IAH<br>destination: CLT<br>arrival_delay: 4.62","origin: JFK<br>destination: CLT<br>arrival_delay: 12.31","origin: LGA<br>destination: CLT<br>arrival_delay: 7.07","origin: ORD<br>destination: CLT<br>arrival_delay: 9.3"],["origin: ATL<br>destination: DCA<br>arrival_delay: 7.61","origin: CLT<br>destination: DCA<br>arrival_delay: 5.87",null,"origin: DEN<br>destination: DCA<br>arrival_delay: 6.33","origin: DFW<br>destination: DCA<br>arrival_delay: 6.84","origin: IAD<br>destination: DCA<br>arrival_delay: 8.21","origin: IAH<br>destination: DCA<br>arrival_delay: 3.66","origin: JFK<br>destination: DCA<br>arrival_delay: 9.94","origin: LGA<br>destination: DCA<br>arrival_delay: 0.37","origin: ORD<br>destination: DCA<br>arrival_delay: 8.36"],["origin: ATL<br>destination: DEN<br>arrival_delay: 7.57","origin: CLT<br>destination: DEN<br>arrival_delay: 5.49","origin: DCA<br>destination: DEN<br>arrival_delay: 1.88",null,"origin: DFW<br>destination: DEN<br>arrival_delay: 8.04","origin: IAD<br>destination: DEN<br>arrival_delay: 6.81","origin: IAH<br>destination: DEN<br>arrival_delay: 6.5","origin: JFK<br>destination: DEN<br>arrival_delay: 10.27","origin: LGA<br>destination: DEN<br>arrival_delay: 7.28","origin: ORD<br>destination: DEN<br>arrival_delay: 10.06"],["origin: ATL<br>destination: DFW<br>arrival_delay: 8.63","origin: CLT<br>destination: DFW<br>arrival_delay: 4.03","origin: DCA<br>destination: DFW<br>arrival_delay: 3.37","origin: DEN<br>destination: DFW<br>arrival_delay: 7.17",null,"origin: IAD<br>destination: DFW<br>arrival_delay: 3.88","origin: IAH<br>destination: DFW<br>arrival_delay: 6.29","origin: JFK<br>destination: DFW<br>arrival_delay: 14.73","origin: LGA<br>destination: DFW<br>arrival_delay: 4.38","origin: ORD<br>destination: DFW<br>arrival_delay: 7.08"],["origin: ATL<br>destination: IAD<br>arrival_delay: 8.56","origin: CLT<br>destination: IAD<br>arrival_delay: 6.49","origin: DCA<br>destination: IAD<br>arrival_delay: -4.43","origin: DEN<br>destination: IAD<br>arrival_delay: 6.34","origin: DFW<br>destination: IAD<br>arrival_delay: 6.35",null,"origin: IAH<br>destination: IAD<br>arrival_delay: 3.42","origin: JFK<br>destination: IAD<br>arrival_delay: 8.29","origin: LGA<br>destination: IAD<br>arrival_delay: 8.05","origin: ORD<br>destination: IAD<br>arrival_delay: 9.86"],["origin: ATL<br>destination: IAH<br>arrival_delay: 8.6","origin: CLT<br>destination: IAH<br>arrival_delay: 5.94","origin: DCA<br>destination: IAH<br>arrival_delay: 2.68","origin: DEN<br>destination: IAH<br>arrival_delay: 7","origin: DFW<br>destination: IAH<br>arrival_delay: 7.43","origin: IAD<br>destination: IAH<br>arrival_delay: 6",null,"origin: JFK<br>destination: IAH<br>arrival_delay: 9.35","origin: LGA<br>destination: IAH<br>arrival_delay: 6.03","origin: ORD<br>destination: IAH<br>arrival_delay: 9.12"],["origin: ATL<br>destination: JFK<br>arrival_delay: 11.45","origin: CLT<br>destination: JFK<br>arrival_delay: 13.01","origin: DCA<br>destination: JFK<br>arrival_delay: 11.04","origin: DEN<br>destination: JFK<br>arrival_delay: 7.26","origin: DFW<br>destination: JFK<br>arrival_delay: 10.85","origin: IAD<br>destination: JFK<br>arrival_delay: 12.64","origin: IAH<br>destination: JFK<br>arrival_delay: 8.2",null,null,"origin: ORD<br>destination: JFK<br>arrival_delay: 12.31"],["origin: ATL<br>destination: LGA<br>arrival_delay: 13.2","origin: CLT<br>destination: LGA<br>arrival_delay: 11.45","origin: DCA<br>destination: LGA<br>arrival_delay: 2.43","origin: DEN<br>destination: LGA<br>arrival_delay: 11.17","origin: DFW<br>destination: LGA<br>arrival_delay: 10.25","origin: IAD<br>destination: LGA<br>arrival_delay: 11.96","origin: IAH<br>destination: LGA<br>arrival_delay: 10.88",null,null,"origin: ORD<br>destination: LGA<br>arrival_delay: 11.15"],["origin: ATL<br>destination: ORD<br>arrival_delay: 11.9","origin: CLT<br>destination: ORD<br>arrival_delay: 9.8","origin: DCA<br>destination: ORD<br>arrival_delay: 6.1","origin: DEN<br>destination: ORD<br>arrival_delay: 10.53","origin: DFW<br>destination: ORD<br>arrival_delay: 9.5","origin: IAD<br>destination: ORD<br>arrival_delay: 8.33","origin: IAH<br>destination: ORD<br>arrival_delay: 11.06","origin: JFK<br>destination: ORD<br>arrival_delay: 17.36","origin: LGA<br>destination: ORD<br>arrival_delay: 7.86",null]],"colorscale":[[0,"#FFFFFF"],[0.220455537114002,"#D8E2EE"],[0.235121036168544,"#D6E0ED"],[0.289705771862716,"#CCD9E9"],[0.314995103343137,"#C8D6E7"],[0.326265883472013,"#C6D4E6"],[0.358126994221729,"#C0D0E4"],[0.360495253604851,"#C0D0E4"],[0.371211099757297,"#BECFE3"],[0.381529665092533,"#BCCDE2"],[0.388401707258818,"#BBCCE2"],[0.390148951560722,"#BBCCE2"],[0.392950543566392,"#BACCE1"],[0.404471396793396,"#B8CAE1"],[0.413720353617263,"#B6C9E0"],[0.415191062301563,"#B6C9E0"],[0.417954445634229,"#B6C9E0"],[0.41856645037478,"#B6C9DF"],[0.422893881898291,"#B5C8DF"],[0.431219820318448,"#B3C7DF"],[0.455340818477051,"#AFC4DD"],[0.47254206702059,"#ACC2DB"],[0.475824911365917,"#ABC1DB"],[0.478614059959527,"#ABC1DB"],[0.478892106542017,"#ABC1DB"],[0.479956367425385,"#ABC1DB"],[0.483269520157869,"#AAC1DB"],[0.483323215537141,"#AAC1DB"],[0.491994416464964,"#A9BFDA"],[0.49379845405737,"#A8BFDA"],[0.494277382737415,"#A8BFDA"],[0.4949483797451,"#A8BFDA"],[0.495561027048762,"#A8BFDA"],[0.500382731139362,"#A7BED9"],[0.50128925203263,"#A7BED9"],[0.501481367157469,"#A7BED9"],[0.51572385106483,"#A4BCD8"],[0.517253988203036,"#A4BCD8"],[0.524674898543362,"#A3BBD7"],[0.526218875795656,"#A2BBD7"],[0.527958749889444,"#A2BBD7"],[0.527959075751454,"#A2BBD7"],[0.52810844655813,"#A2BBD7"],[0.528429427827822,"#A2BBD7"],[0.532355896409273,"#A1BAD7"],[0.53663057361579,"#A1BAD7"],[0.537271786336865,"#A1BAD7"],[0.539622151058074,"#A0B9D6"],[0.544286048832883,"#9FB9D6"],[0.550064527797597,"#9EB8D6"],[0.550608220037991,"#9EB8D6"],[0.552503822806452,"#9EB8D5"],[0.560446824006759,"#9CB7D5"],[0.563974555015312,"#9CB6D5"],[0.572198162858736,"#9AB5D4"],[0.572680561027596,"#9AB5D4"],[0.575508881420848,"#9AB5D4"],[0.579615907525195,"#99B4D3"],[0.580208947203045,"#99B4D3"],[0.580948911381854,"#99B4D3"],[0.583528936440087,"#98B4D3"],[0.585397080131902,"#98B4D3"],[0.586887051834747,"#98B4D3"],[0.588320991174162,"#97B3D3"],[0.592529207537495,"#97B3D2"],[0.593785183966634,"#96B3D2"],[0.596156972849592,"#96B2D2"],[0.597908251140293,"#96B2D2"],[0.599152232086551,"#95B2D2"],[0.606979625543442,"#94B1D1"],[0.617041907482155,"#92B0D1"],[0.621975497300887,"#91AFD0"],[0.629939981047246,"#90AED0"],[0.632307970936729,"#8FAECF"],[0.637930784007805,"#8EADCF"],[0.639263911488244,"#8EADCF"],[0.652862949154039,"#8CABCE"],[0.655904901246423,"#8BABCE"],[0.659552591737778,"#8AABCD"],[0.661827807649112,"#8AAACD"],[0.664792527515765,"#89AACD"],[0.673842272879803,"#88A9CC"],[0.674510392168591,"#88A9CC"],[0.679733144401821,"#87A8CC"],[0.686424293549738,"#86A7CB"],[0.695737837523735,"#84A6CB"],[0.701170387224551,"#83A6CA"],[0.702422145601397,"#83A5CA"],[0.706186984944412,"#82A5CA"],[0.706310281044572,"#82A5CA"],[0.710030314747219,"#81A4CA"],[0.710643132564431,"#81A4CA"],[0.714806355914222,"#80A4C9"],[0.715728072369897,"#80A4C9"],[0.718025885066374,"#80A3C9"],[0.722292138029002,"#7FA3C9"],[0.728650036372322,"#7EA2C8"],[0.728801354712092,"#7EA2C8"],[0.729152775028315,"#7EA2C8"],[0.749297992062937,"#7AA0C7"],[0.752150813914015,"#799FC6"],[0.768124363798173,"#769DC5"],[0.768243360314104,"#769DC5"],[0.783289233033361,"#739CC4"],[0.800136892737496,"#709AC3"],[0.80914732187602,"#6E99C2"],[0.879366384928629,"#6090BD"],[1,"#4682B4"]],"type":"heatmap","showscale":false,"autocolorscale":false,"showlegend":false,"xaxis":"x","yaxis":"y","hoverinfo":"text","name":""},{"x":[0.4,10.6],"y":[0.4,12.6],"name":"99_5251e46a06ff20cb5bb7f42212b46bc7","type":"scatter","mode":"markers","opacity":0,"hoverinfo":"none","showlegend":false,"marker":{"color":[0,1],"colorscale":[[0,"#FCFCFD"],[0.0476190476190476,"#F3F6FA"],[0.0952380952380952,"#EBF0F7"],[0.142857142857143,"#E3EAF3"],[0.19047619047619,"#DBE4F0"],[0.238095238095238,"#D3DEEC"],[0.285714285714286,"#CBD8E9"],[0.333333333333333,"#C3D3E5"],[0.380952380952381,"#BBCDE2"],[0.428571428571429,"#B3C7DE"],[0.476190476190476,"#ABC1DB"],[0.523809523809524,"#A3BBD8"],[0.571428571428571,"#9BB6D4"],[0.619047619047619,"#92B0D1"],[0.666666666666667,"#8AAACD"],[0.714285714285714,"#82A5CA"],[0.761904761904762,"#799FC6"],[0.80952380952381,"#709AC3"],[0.857142857142857,"#6794BF"],[0.904761904761905,"#5E8FBC"],[0.952380952380952,"#5489B9"],[1,"#4A84B5"]],"colorbar":{"bgcolor":"rgba(255,255,255,1)","bordercolor":"transparent","borderwidth":1.88976377952756,"thickness":23.04,"title":"arrival_delay","titlefont":{"color":"rgba(0,0,0,1)","family":"","size":15.9402241594022},"tickmode":"array","ticktext":["0","5","10","15"],"tickvals":[0.19047619047619,0.428571428571429,0.666666666666667,0.904761904761905],"tickfont":{"color":"rgba(0,0,0,1)","family":"","size":12.7521793275218},"ticklen":2,"len":0.5}}}],"layout":{"margin":{"b":43.8356164383562,"l":47.0236612702366,"t":27.1581569115816,"r":7.97011207970112},"plot_bgcolor":"rgba(255,255,255,1)","paper_bgcolor":"rgba(255,255,255,1)","font":{"color":"rgba(0,0,0,1)","family":"","size":15.9402241594022},"xaxis":{"type":"linear","autorange":false,"tickmode":"array","range":[0.4,10.6],"ticktext":["ATL","CLT","DCA","DEN","DFW","IAD","IAH","JFK","LGA","ORD"],"tickvals":[1,2,3,4,5,6,7,8,9,10],"ticks":"outside","tickcolor":"rgba(0,0,0,1)","ticklen":3.98505603985056,"tickwidth":0.66417600664176,"showticklabels":true,"tickfont":{"color":"rgba(0,0,0,1)","family":"","size":12.7521793275218},"tickangle":-0,"showline":false,"linecolor":null,"linewidth":0,"showgrid":true,"domain":[0,1],"gridcolor":"rgba(229,229,229,1)","gridwidth":0.265670402656704,"zeroline":false,"anchor":"y","title":"origin","titlefont":{"color":"rgba(0,0,0,1)","family":"","size":15.9402241594022},"hoverformat":".2f"},"yaxis":{"type":"linear","autorange":false,"tickmode":"array","range":[0.4,12.6],"ticktext":["ATL","BDL","BOS","CLT","DCA","DEN","DFW","IAD","IAH","JFK","LGA","ORD"],"tickvals":[1,2,3,4,5,6,7,8,9,10,11,12],"ticks":"outside","tickcolor":"rgba(0,0,0,1)","ticklen":3.98505603985056,"tickwidth":0.66417600664176,"showticklabels":true,"tickfont":{"color":"rgba(0,0,0,1)","family":"","size":12.7521793275218},"tickangle":-0,"showline":false,"linecolor":null,"linewidth":0,"showgrid":true,"domain":[0,1],"gridcolor":"rgba(229,229,229,1)","gridwidth":0.265670402656704,"zeroline":false,"anchor":"x","title":"destination","titlefont":{"color":"rgba(0,0,0,1)","family":"","size":15.9402241594022},"hoverformat":".2f"},"shapes":[{"type":"rect","fillcolor":"transparent","line":{"color":"rgba(127,127,127,1)","width":0.66417600664176,"linetype":"solid"},"yref":"paper","xref":"paper","x0":0,"x1":1,"y0":0,"y1":1}],"showlegend":false,"legend":{"bgcolor":"rgba(255,255,255,1)","bordercolor":"transparent","borderwidth":1.88976377952756,"font":{"color":"rgba(0,0,0,1)","family":"","size":12.7521793275218},"y":1},"hovermode":"closest"},"width":650,"source":"A","config":{"modeBarButtonsToRemove":["sendDataToCloud"]},"base_url":"https://plot.ly"},"evals":[],"jsHooks":[]}</script></p>
</div>
</div>
<div id="data-manipulation-with-sparkr" class="section level1">
<h1><span class="header-section-number">3</span> Data Manipulation with SparkR</h1>
<p>Now that we have our two datasets saved as Spark DataFrames, we can conduct standard data manipulation techniques to visualize and explore our data.</p>
<p>First, we’ll use the <code>rename</code> function to rename our columns, and the <code>select</code> function to select the columns we need. We’ll also transform the These SparkR functions look just like the verbs from the <code>dplyr</code> package for data manipulation, but are designed to work with Spark DataFrames.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">system.time</span>(airDF &lt;-<span class="st"> </span><span class="kw">rename</span>(airDF,
                            <span class="dt">ArrDel15 =</span> airDF$ARR_DEL15,
                            <span class="dt">Year =</span> airDF$YEAR,
                            <span class="dt">Month =</span> airDF$MONTH,
                            <span class="dt">DayofMonth =</span> airDF$DAY_OF_MONTH,
                            <span class="dt">DayOfWeek =</span> airDF$DAY_OF_WEEK,
                            <span class="dt">Carrier =</span> airDF$UNIQUE_CARRIER,
                            <span class="dt">OriginAirportID =</span> airDF$ORIGIN_AIRPORT_ID,
                            <span class="dt">DestAirportID =</span> airDF$DEST_AIRPORT_ID,
                            <span class="dt">CRSDepTime =</span> airDF$CRS_DEP_TIME,
                            <span class="dt">CRSArrTime =</span>  airDF$CRS_ARR_TIME,
                            <span class="dt">Distance =</span> airDF$DISTANCE,
                            <span class="dt">DepDelay =</span> airDF$DEP_DELAY,
                            <span class="dt">ArrDelay =</span> airDF$ARR_DELAY
                            )
            )
  <span class="co">#  user  system elapsed </span>
  <span class="co"># 0.136   0.000   0.242 </span>

<span class="co"># Select desired columns from the flight data. </span>
varsToKeep &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;ArrDel15&quot;</span>, <span class="st">&quot;Year&quot;</span>, <span class="st">&quot;Month&quot;</span>, <span class="st">&quot;DayofMonth&quot;</span>, <span class="st">&quot;DayOfWeek&quot;</span>, <span class="st">&quot;Carrier&quot;</span>,
                <span class="st">&quot;OriginAirportID&quot;</span>, <span class="st">&quot;DestAirportID&quot;</span>, <span class="st">&quot;CRSDepTime&quot;</span>, <span class="st">&quot;CRSArrTime&quot;</span>,
                <span class="st">&quot;Distance&quot;</span>, <span class="st">&quot;DepDelay&quot;</span>, <span class="st">&quot;ArrDelay&quot;</span>)
<span class="kw">system.time</span>(airDF &lt;-<span class="st"> </span><span class="kw">select</span>(airDF, varsToKeep))
  <span class="co">#  user  system elapsed </span>
  <span class="co"># 0.064   0.000   0.112 </span>

<span class="co"># Round down scheduled departure time to full hour.</span>
<span class="kw">system.time</span>(airDF$CRSDepTime &lt;-<span class="st"> </span><span class="kw">floor</span>(airDF$CRSDepTime /<span class="st"> </span><span class="dv">100</span>))
  <span class="co"># user  system elapsed </span>
  <span class="co">#  0.00    0.00    0.06 </span></code></pre></div>
<div id="data-aggregations" class="section level2">
<h2><span class="header-section-number">3.1</span> Data Aggregations</h2>
<p>SparkR is great at merges, and data aggregation. For instance, suppose we want to see the average departure delay for each carrier and arrange it in descending order. The following example shows just how easy the syntax for SparkR is.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">sum_df &lt;-<span class="st"> </span>airDF %&gt;%<span class="st"> </span><span class="kw">select</span>(<span class="st">&quot;Carrier&quot;</span>, <span class="st">&quot;DepDelay&quot;</span>) %&gt;%<span class="st"> </span>
<span class="st">  </span><span class="kw">group_by</span>(airDF$Carrier) %&gt;%<span class="st"> </span>
<span class="st">  </span><span class="kw">summarize</span>(<span class="dt">count =</span> <span class="kw">n</span>(airDF$Carrier), 
            <span class="dt">ave_delay =</span> <span class="kw">mean</span>(airDF$DepDelay))
   <span class="co"># user  system elapsed </span>
  <span class="co"># 0.024   0.000   0.055 </span></code></pre></div>
<p>The syntax is almost exactly like the syntax from the dplyr package, and the <code>%&gt;%</code> operator makes chaining the additive methods exceptionally simple. Note that the above operation will not be run until we call an action upon the <code>sum_df.</code> As of right now it is a series of transformations, so it is a recipe for doing some computations, but the actual evaluation has been deferred until we call an action.</p>
</div>
<div id="collecting-results-to-local-dataframes" class="section level2">
<h2><span class="header-section-number">3.2</span> Collecting Results to Local Dataframes</h2>
<p>In order to evaluate and bring the summarized data into an R <code>data.frame</code>, we can use the <code>collect</code> action.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">sum_local &lt;-<span class="st"> </span>sum_df %&gt;%<span class="st"> </span><span class="kw">collect</span>()
  <span class="co">#  user  system elapsed </span>
  <span class="co"># 0.616   0.536 337.758 </span>
<span class="kw">library</span>(dplyr)
sum_local %&gt;%<span class="st"> </span><span class="kw">arrange</span>(<span class="kw">desc</span>(ave_delay))</code></pre></div>
</div>
<div id="dimple-bar-charts" class="section level2">
<h2><span class="header-section-number">3.3</span> Dimple Bar Charts</h2>
<p>Now that our data resides as a local data.frame, we can plot it using any R plotting library.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">load</span>(<span class="st">&quot;local_df.RData&quot;</span>)
<span class="kw">library</span>(rcdimple)</code></pre></div>
<pre><code>## Loading required package: htmlwidgets</code></pre>
<pre><code>## Loading required package: htmltools</code></pre>
<pre><code>## 
## Attaching package: &#39;rcdimple&#39;</code></pre>
<pre><code>## The following object is masked from &#39;package:ggplot2&#39;:
## 
##     facet</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">sum_local %&gt;%<span class="st"> </span>
<span class="st">  </span><span class="kw">dimple</span>(<span class="dt">x =</span><span class="st">&quot;Carrier&quot;</span>, <span class="dt">y =</span> <span class="st">&quot;ave_delay&quot;</span>, <span class="dt">z =</span>  <span class="st">&quot;count&quot;</span>, <span class="dt">type =</span> <span class="st">&quot;bar&quot;</span>) %&gt;%
<span class="st">  </span><span class="kw">add_title</span>(<span class="dt">html =</span> <span class="st">&quot;&lt;h4&gt;Average Delay in Minutes by Carrier&lt;/h4&gt;&quot;</span> ) %&gt;%<span class="st"> </span>
<span class="st">  </span><span class="kw">zAxis</span>(<span class="dt">outputFormat =</span> <span class="st">&quot;#,### &quot;</span>)</code></pre></div>
<p><div id="htmlwidget-1864" style="width:672px;height:480px;" class="dimple html-widget"></div>
<script type="application/json" data-for="htmlwidget-1864">{"x":{"options":{"chart":[],"xAxis":{"type":"addCategoryAxis"},"yAxis":{"type":"addMeasureAxis"},"zAxis":{"type":"addMeasureAxis","outputFormat":"#,### "},"colorAxis":[],"defaultColors":[],"layers":[],"legend":[],"x":"Carrier","y":"ave_delay","type":"bar","z":"count","title":{"text":null,"html":"<h4>Average Delay in Minutes by Carrier\u003c/h4>"}},"data":{"Carrier":["AA","PA (1)","TW","TZ","HA","AS","UA","B6","NW","HP","US","OH","OO","PI","VX","CO","ML (1)","PS","WN","DH","DL","KH","XE","EA","EV","F9","9E","YV","FL","MQ"],"count":[17140606,316167,3757747,208420,555683,3443588,14862404,1652137,10585760,3636682,15709733,1765828,5443169,873957,54742,8888536,70622,83617,20529039,693047,19168060,154381,3459389,919785,3384793,670653,1045396,1563254,2232262,5750198],"ave_delay":[8.09216330413803,5.53244244289068,7.65825114221727,5.55423481294241,-0.470471755160245,7.24013290246557,9.6410715967209,10.9892686446028,6.02139368193511,8.10779026658562,6.99896030027832,9.52695744411818,6.95087777743635,9.56033602798461,10.0396614090817,7.81891288846895,6.2296766743649,8.92810370334441,9.32814933847665,9.61263938968893,7.55365844885708,1.59931768991184,8.55590331293135,8.67405056543554,12.7600643883231,6.82652221551061,6.8708289697235,9.63959007239046,8.28258416166276,8.69911067862048]}},"evals":[],"jsHooks":[]}</script></p>
<p>In order to make the weather data correspond to the airline data, let us aggregate it by date and airport, and obtain it’s average value. If you are familiar with the dplyr package, you should be very familiar with the syntax provided by SparkR.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">weatherAgg &lt;-<span class="st"> </span>weatherDF %&gt;%<span class="st"> </span>
<span class="st">  </span>SparkR::<span class="kw">group_by</span>(<span class="st">&quot;AdjustedYear&quot;</span>, <span class="st">&quot;AdjustedMonth&quot;</span>, <span class="st">&quot;AdjustedDay&quot;</span>, <span class="st">&quot;AdjustedHour&quot;</span>, <span class="st">&quot;AirportID&quot;</span>) %&gt;%
<span class="st">  </span>SparkR::<span class="kw">summarize</span>(<span class="dt">Visibility =</span> <span class="kw">mean</span>(weatherDF$Visibility),
                    <span class="dt">DryBulbCelsius =</span> <span class="kw">mean</span>(weatherDF$DryBulbCelsius),
                    <span class="dt">DewPointCelsius =</span> <span class="kw">mean</span>(weatherDF$DewPointCelsius),
                    <span class="dt">RelativeHumidity =</span> <span class="kw">mean</span>(weatherDF$RelativeHumidity),
                    <span class="dt">WindSpeed =</span> <span class="kw">mean</span>(weatherDF$RelativeHumidity),
                    <span class="dt">Altimeter =</span> <span class="kw">mean</span>(weatherDF$Altimeter))</code></pre></div>
</div>
<div id="merging-data" class="section level2">
<h2><span class="header-section-number">3.4</span> Merging Data</h2>
<p>We can use SparkR for merging data sets as well. Let’s merge the airlines dataset with the weather dataset. We’ll first add weather data to the origination airport, and then add it to the destination airport. To keep our data in manageable size, we will remove the redundant columns. Finally, we save the DataFrame to a CSV file, stored in HDFS so that we may access it later.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">joinedDF &lt;-<span class="st"> </span>SparkR::<span class="kw">join</span>(
  airDF,
  weatherAgg,
  airDF$OriginAirportID ==<span class="st"> </span>weatherAgg$AirportID &amp;
<span class="st">    </span>airDF$Year ==<span class="st"> </span>weatherAgg$AdjustedYear &amp;
<span class="st">    </span>airDF$Month ==<span class="st"> </span>weatherAgg$AdjustedMonth &amp;
<span class="st">    </span>airDF$DayofMonth ==<span class="st"> </span>weatherAgg$AdjustedDay &amp;
<span class="st">    </span>airDF$CRSDepTime ==<span class="st"> </span>weatherAgg$AdjustedHour,
  <span class="dt">joinType =</span> <span class="st">&quot;left_outer&quot;</span>
)

vars &lt;-<span class="st"> </span><span class="kw">names</span>(joinedDF)
varsToDrop &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="st">&#39;AdjustedYear&#39;</span>, <span class="st">&#39;AdjustedMonth&#39;</span>, <span class="st">&#39;AdjustedDay&#39;</span>, <span class="st">&#39;AdjustedHour&#39;</span>, <span class="st">&#39;AirportID&#39;</span>)
varsToKeep &lt;-<span class="st"> </span>vars[!(vars %in%<span class="st"> </span>varsToDrop)]
joinedDF1 &lt;-<span class="st"> </span><span class="kw">select</span>(joinedDF, varsToKeep)

joinedDF2 &lt;-<span class="st"> </span><span class="kw">rename</span>(joinedDF1,
                    <span class="dt">VisibilityOrigin =</span> joinedDF1$Visibility,
                    <span class="dt">DryBulbCelsiusOrigin =</span> joinedDF1$DryBulbCelsius,
                    <span class="dt">DewPointCelsiusOrigin =</span> joinedDF1$DewPointCelsius,
                    <span class="dt">RelativeHumidityOrigin =</span> joinedDF1$RelativeHumidity,
                    <span class="dt">WindSpeedOrigin =</span> joinedDF1$WindSpeed,
                    <span class="dt">AltimeterOrigin =</span> joinedDF1$Altimeter
)


joinedDF3 &lt;-<span class="st"> </span><span class="kw">join</span>(
  joinedDF2,
  weatherAgg,
  airDF$DestAirportID ==<span class="st"> </span>weatherAgg$AirportID &amp;
<span class="st">    </span>airDF$Year ==<span class="st"> </span>weatherAgg$AdjustedYear &amp;
<span class="st">    </span>airDF$Month ==<span class="st"> </span>weatherAgg$AdjustedMonth &amp;
<span class="st">    </span>airDF$DayofMonth ==<span class="st"> </span>weatherAgg$AdjustedDay &amp;
<span class="st">    </span>airDF$CRSDepTime ==<span class="st"> </span>weatherAgg$AdjustedHour,
  <span class="dt">joinType =</span> <span class="st">&quot;left_outer&quot;</span>
)

<span class="co"># Remove redundant columns</span>
vars &lt;-<span class="st"> </span><span class="kw">names</span>(joinedDF3)
varsToDrop &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="st">&#39;AdjustedYear&#39;</span>, <span class="st">&#39;AdjustedMonth&#39;</span>, <span class="st">&#39;AdjustedDay&#39;</span>, <span class="st">&#39;AdjustedHour&#39;</span>, <span class="st">&#39;AirportID&#39;</span>)
varsToKeep &lt;-<span class="st"> </span>vars[!(vars %in%<span class="st"> </span>varsToDrop)]
joinedDF4 &lt;-<span class="st"> </span><span class="kw">select</span>(joinedDF3, varsToKeep)

joinedDF5 &lt;-<span class="st"> </span><span class="kw">rename</span>(joinedDF4,
                    <span class="dt">VisibilityDest =</span> joinedDF4$Visibility,
                    <span class="dt">DryBulbCelsiusDest =</span> joinedDF4$DryBulbCelsius,
                    <span class="dt">DewPointCelsiusDest =</span> joinedDF4$DewPointCelsius,
                    <span class="dt">RelativeHumidityDest =</span> joinedDF4$RelativeHumidity,
                    <span class="dt">WindSpeedDest =</span> joinedDF4$WindSpeed,
                    <span class="dt">AltimeterDest =</span> joinedDF4$Altimeter
                    )


joinedDF5 &lt;-<span class="st"> </span><span class="kw">repartition</span>(joinedDF5, <span class="dv">80</span>) 

<span class="co"># write result to directory of CSVs</span>
<span class="kw">write.df</span>(joinedDF5, <span class="kw">file.path</span>(<span class="st">&quot;/user/RevoShare/alizaidi/delayDataLarge&quot;</span>,
                              <span class="st">&quot;JoinAirWeatherDelay&quot;</span>),
         <span class="st">&quot;com.databricks.spark.csv&quot;</span>, <span class="st">&quot;overwrite&quot;</span>, 
         <span class="dt">header =</span> <span class="st">&quot;true&quot;</span>)

<span class="co"># We can shut down the SparkR Spark context now</span>
<span class="kw">sparkR.stop</span>()</code></pre></div>
</div>
<div id="exploring-credit-scores-for-mortgage-borrowers" class="section level2">
<h2><span class="header-section-number">3.5</span> Exploring Credit Scores for Mortgage Borrowers</h2>
<p>We will examine a very different dataset in this section.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">data_dir &lt;-<span class="st"> &quot;/user/RevoShare/alizaidi&quot;</span></code></pre></div>
</div>
</div>
<!--bookdown:body:end-->
            </section>

          </div>
        </div>
      </div>
<!--bookdown:link_prev-->
<!--bookdown:link_next-->

<!--bookdown:config-->

</body>

</html>
